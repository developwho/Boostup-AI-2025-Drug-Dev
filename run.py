#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CYP3A4 ëª¨ë¸ ì „ì²´ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
í•™ìŠµ â†’ ì¶”ë¡ ì„ ìˆœì°¨ì ìœ¼ë¡œ ìˆ˜í–‰
"""

import os
import sys
import time
import subprocess
from pathlib import Path

def check_environment():
    """ì‹¤í–‰ í™˜ê²½ ì²´í¬"""
    print("=== í™˜ê²½ ì²´í¬ ===")
    
    # í•„ìˆ˜ íŒŒì¼ í™•ì¸
    required_files = ['train.csv', 'test.csv', 'requirements.txt']
    missing_files = []
    
    for file in required_files:
        if not Path(file).exists():
            missing_files.append(file)
    
    if missing_files:
        print(f"âŒ í•„ìˆ˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_files}")
        return False
    
    print("âœ… í•„ìˆ˜ íŒŒì¼ í™•ì¸ ì™„ë£Œ")
    
    # Python ë²„ì „ í™•ì¸
    python_version = sys.version_info
    if python_version.major < 3 or (python_version.major == 3 and python_version.minor < 8):
        print(f"âŒ Python 3.8 ì´ìƒì´ í•„ìš”í•©ë‹ˆë‹¤. í˜„ì¬: {python_version.major}.{python_version.minor}")
        return False
    
    print(f"âœ… Python ë²„ì „: {python_version.major}.{python_version.minor}.{python_version.micro}")
    
    # ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸
    try:
        import torch
        import torch_geometric
        import lightgbm
        import rdkit
        import sklearn
        import pandas
        import numpy
        
        print("âœ… í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸ ì™„ë£Œ")
        print(f"  - PyTorch: {torch.__version__}")
        print(f"  - PyTorch Geometric: {torch_geometric.__version__}")
        print(f"  - LightGBM: {lightgbm.__version__}")
        print(f"  - RDKit: {rdkit.__version__}")
        print(f"  - scikit-learn: {sklearn.__version__}")
        print(f"  - pandas: {pandas.__version__}")
        print(f"  - numpy: {numpy.__version__}")
        
        # GPU í™•ì¸
        if torch.cuda.is_available():
            print(f"âœ… CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name(0)}")
            print(f"  - CUDA ë²„ì „: {torch.version.cuda}")
            print(f"  - GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
        else:
            print("âš ï¸  CUDA ì‚¬ìš© ë¶ˆê°€ëŠ¥ (CPU ëª¨ë“œë¡œ ì‹¤í–‰)")
            
    except ImportError as e:
        print(f"âŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëˆ„ë½: {e}")
        print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install -r requirements.txt")
        return False
    
    return True

def run_training():
    """í•™ìŠµ ì‹¤í–‰"""
    print("\n=== ëª¨ë¸ í•™ìŠµ ì‹œì‘ ===")
    print("ì˜ˆìƒ ì†Œìš” ì‹œê°„: 2-3ì‹œê°„ (GPU) / 6-8ì‹œê°„ (CPU)")
    
    start_time = time.time()
    
    try:
        # train.py ì‹¤í–‰
        result = subprocess.run([sys.executable, 'train.py'], 
                              capture_output=True, text=True, check=True)
        
        print("âœ… í•™ìŠµ ì™„ë£Œ!")
        print(result.stdout[-500:])  # ë§ˆì§€ë§‰ 500ìë§Œ ì¶œë ¥
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:")
        print(e.stderr)
        return False
    
    elapsed_time = time.time() - start_time
    print(f"â° í•™ìŠµ ì†Œìš” ì‹œê°„: {elapsed_time/3600:.1f}ì‹œê°„")
    
    return True

def run_inference():
    """ì¶”ë¡  ì‹¤í–‰"""
    print("\n=== ëª¨ë¸ ì¶”ë¡  ì‹œì‘ ===")
    print("ì˜ˆìƒ ì†Œìš” ì‹œê°„: 5-10ë¶„")
    
    start_time = time.time()
    
    try:
        # inference.py ì‹¤í–‰
        result = subprocess.run([sys.executable, 'inference.py'], 
                              capture_output=True, text=True, check=True)
        
        print("âœ… ì¶”ë¡  ì™„ë£Œ!")
        print(result.stdout[-500:])  # ë§ˆì§€ë§‰ 500ìë§Œ ì¶œë ¥
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ ë°œìƒ:")
        print(e.stderr)
        return False
    
    elapsed_time = time.time() - start_time
    print(f"â° ì¶”ë¡  ì†Œìš” ì‹œê°„: {elapsed_time:.1f}ì´ˆ")
    
    return True

def check_results():
    """ê²°ê³¼ íŒŒì¼ í™•ì¸"""
    print("\n=== ê²°ê³¼ í™•ì¸ ===")
    
    # ìƒì„±ë˜ì–´ì•¼ í•  íŒŒì¼ë“¤
    expected_files = [
        'stacking_submission.csv',
        'lgbm_submission.csv', 
        'gnn_submission.csv'
    ]
    
    expected_model_files = [
        'models/stacking_meta_model.pkl',
        'models/lgbm_test_preds.npy',
        'models/gnn_test_preds.npy'
    ] + [f'models/lgbm_fold_{i}.pkl' for i in range(5)] + \
        [f'models/gnn_fold_{i}.pth' for i in range(5)]
    
    all_files = expected_files + expected_model_files
    missing_files = []
    
    for file in all_files:
        if not Path(file).exists():
            missing_files.append(file)
    
    if missing_files:
        print(f"âš ï¸  ì¼ë¶€ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {missing_files}")
        return False
    
    print("âœ… ëª¨ë“  ê²°ê³¼ íŒŒì¼ ìƒì„± ì™„ë£Œ")
    
    # ì œì¶œ íŒŒì¼ í†µê³„ í™•ì¸
    try:
        import pandas as pd
        submission = pd.read_csv('stacking_submission.csv')
        
        print(f"\nğŸ“Š ìµœì¢… ì œì¶œ íŒŒì¼ í†µê³„:")
        print(f"  - ìƒ˜í”Œ ìˆ˜: {len(submission)}")
        print(f"  - í‰ê· : {submission['Inhibition'].mean():.2f}")
        print(f"  - ì¤‘ì•™ê°’: {submission['Inhibition'].median():.2f}")
        print(f"  - í‘œì¤€í¸ì°¨: {submission['Inhibition'].std():.2f}")
        print(f"  - ë²”ìœ„: {submission['Inhibition'].min():.2f} ~ {submission['Inhibition'].max():.2f}")
        
        # ì´ìƒê°’ ì²´í¬
        if submission['Inhibition'].min() < 0 or submission['Inhibition'].max() > 100:
            print("âš ï¸  ì˜ˆì¸¡ê°’ì´ ì˜ˆìƒ ë²”ìœ„(0-100)ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤.")
        else:
            print("âœ… ì˜ˆì¸¡ê°’ì´ ì •ìƒ ë²”ìœ„ ë‚´ì— ìˆìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"âš ï¸  ì œì¶œ íŒŒì¼ í†µê³„ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
    
    return True

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ CYP3A4 ëª¨ë¸ ì „ì²´ ì‹¤í–‰ ì‹œì‘")
    print("=" * 50)
    
    # 1. í™˜ê²½ ì²´í¬
    if not check_environment():
        print("\nâŒ í™˜ê²½ ì²´í¬ ì‹¤íŒ¨. ë¬¸ì œë¥¼ í•´ê²°í•œ í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    # ì‚¬ìš©ì í™•ì¸
    print("\nâš ï¸  í•™ìŠµì—ëŠ” ë§ì€ ì‹œê°„ì´ ì†Œìš”ë©ë‹ˆë‹¤.")
    response = input("ê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").lower().strip()
    
    if response not in ['y', 'yes']:
        print("ì‹¤í–‰ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
        return
    
    total_start_time = time.time()
    
    # 2. í•™ìŠµ ì‹¤í–‰
    if not run_training():
        print("\nâŒ í•™ìŠµ ì‹¤íŒ¨")
        return
    
    # 3. ì¶”ë¡  ì‹¤í–‰
    if not run_inference():
        print("\nâŒ ì¶”ë¡  ì‹¤íŒ¨")
        return
    
    # 4. ê²°ê³¼ í™•ì¸
    if not check_results():
        print("\nâš ï¸  ì¼ë¶€ ê²°ê³¼ íŒŒì¼ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    total_elapsed = time.time() - total_start_time
    
    print("\n" + "=" * 50)
    print("ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
    print(f"â° ì´ ì†Œìš” ì‹œê°„: {total_elapsed/3600:.1f}ì‹œê°„")
    print("\nğŸ“ ìƒì„±ëœ ì£¼ìš” íŒŒì¼:")
    print("  - stacking_submission.csv (ìµœì¢… ì œì¶œ íŒŒì¼)")
    print("  - models/ ë””ë ‰í† ë¦¬ (í•™ìŠµëœ ëª¨ë¸ë“¤)")
    print("\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„:")
    print("  1. stacking_submission.csvë¥¼ ëŒ€íšŒ ì‚¬ì´íŠ¸ì— ì œì¶œ")
    print("  2. Private Score ë³µì› ê²€ì¦ì„ ìœ„í•´ models/ ë””ë ‰í† ë¦¬ ë³´ê´€")
    print("  3. í•„ìš”ì‹œ ì½”ë“œì™€ í•¨ê»˜ ì œì¶œ")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  ì‚¬ìš©ìì— ì˜í•´ ì‹¤í–‰ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("ìì„¸í•œ ì˜¤ë¥˜ ì •ë³´ëŠ” ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
